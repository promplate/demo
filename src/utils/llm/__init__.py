from typing import Literal

from .anthropic import anthropic
from .azure import azure
from .cerebras import cerebras
from .chatglm import glm
from .deepseek import deepseek
from .dispatch import find_llm
from .google import google
from .groq import groq
from .minimax import minimax
from .openai import openai
from .qwen import qwen
from .sambanova import sambanova
from .siliconflow import siliconflow
from .xai import xai
from .yi import yi

openai_compatible_providers = {openai, xai, groq, azure, siliconflow, cerebras, yi}


Model = Literal[
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-0301",
    "gpt-3.5-turbo-0613",
    "gpt-3.5-turbo-1106",
    "gpt-3.5-turbo-0125",
    "gpt-4.1",
    "gpt-4.1-2025-04-14",
    "gpt-4.1-mini",
    "gpt-4.1-mini-2025-04-14",
    "gpt-4.1-nano",
    "gpt-4.1-nano-2025-04-14",
    "o4-mini",
    "o4-mini-2025-04-16",
    "o3",
    "o3-2025-04-16",
    "o3-mini",
    "o3-mini-2025-01-31",
    "o1",
    "o1-2024-12-17",
    "o1-mini",
    "o1-mini-2024-09-12",
    "gpt-4o-mini",
    "gpt-4o-mini-2024-07-18",
    "gpt-4o",
    "gpt-4o-2024-05-13",
    "gpt-4o-2024-08-06",
    "gpt-4o-2024-11-20",
    "gpt-4-1106-preview",
    "gpt-4-0125-preview",
    "gpt-4-turbo",
    "gpt-4-turbo-2024-04-09",
    "azure:gpt-4o",
    "azure:gpt-4o-mini",
    "azure:gpt-4.1",
    "azure:gpt-4.1-mini",
    "azure:gpt-4.1-nano",
    "azure:o1",
    "azure:o3",
    "azure:o1-mini",
    "azure:o3-mini",
    "azure:o4-mini",
    "azure:o1-preview",
    "Mistral-Nemo",
    "Mistral-large",
    "Mistral-large-2407",
    "Mistral-large-2411",
    "Mistral-small",
    "Mistral-small-2503",
    "Codestral-2501",
    "Ministral-3B",
    "Meta-Llama-3.1-405B-Instruct",
    "Meta-Llama-3.1-70B-Instruct",
    "Meta-Llama-3.1-8B-Instruct",
    "Meta-Llama-3-70B-Instruct",
    "Meta-Llama-3-8B-Instruct",
    "Cohere-command-r-plus",
    "Cohere-command-r-plus-08-2024",
    "Cohere-command-r",
    "Cohere-command-r-08-2024",
    "Cohere-command-a",
    "AI21-Jamba-1.5-Large",
    "AI21-Jamba-1.5-Mini",
    "Phi-4",
    "Phi-3.5-MoE-instruct",
    "Phi-3.5-mini-instruct",
    "Phi-3-medium-128k-instruct",
    "Phi-3-medium-4k-instruct",
    "Phi-3-mini-128k-instruct",
    "Phi-3-mini-4k-instruct",
    "Phi-3-small-128k-instruct",
    "Phi-3-small-8k-instruct",
    "MAI-DS-R1",
    "DeepSeek-R1",
    "DeepSeek-V3",
    "chatglm_turbo",
    "claude-3-haiku-20240307",
    "claude-3-sonnet-20240229",
    "qwen-qwq-32b",
    "deepseek-r1-distill-llama-70b",
    "gemma2-9b-it",
    "llama3-8b-8192",
    "llama3-70b-8192",
    "llama-3.1-8b-instant",
    "llama-3.3-70b-versatile",
    "meta-llama/llama-4-scout-17b-16e-instruct",
    "meta-llama/llama-4-maverick-17b-128e-instruct",
    "llama3.1-8b",
    "llama-3.3-70b",
    "llama-4-scout-17b-16e-instruct",
    "llama-4-maverick-17b-128e-instruct",
    "qwen-turbo",
    "qwen-plus",
    "abab5.5s-chat",
    "abab5.5-chat",
    "abab6-chat",
    "Qwen/QwQ-32B-Preview",
    "Qwen/QwQ-32B",
    "Qwen/Qwen2.5-Coder-7B-Instruct",
    "Qwen/Qwen2.5-7B-Instruct",
    "Qwen/Qwen2.5-14B-Instruct",
    "Qwen/Qwen2.5-32B-Instruct",
    "Qwen/Qwen2.5-72B-Instruct",
    "Qwen/Qwen2.5-72B-Instruct-128K",
    "THUDM/GLM-Z1-32B-0414",
    "THUDM/GLM-Z1-9B-0414",
    "THUDM/GLM-4-32B-0414",
    "THUDM/GLM-4-9B-0414",
    "THUDM/glm-4-9b-chat",
    "THUDM/chatglm3-6b",
    "deepseek-ai/DeepSeek-V2.5",
    "deepseek-ai/DeepSeek-V3",
    "deepseek-ai/DeepSeek-R1",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "internlm/internlm2_5-7b-chat",
    "internlm/internlm2_5-20b-chat",
    "yi-lightning",
    "grok-beta",
    "grok-2-1212",
    "grok-3-beta",
    "grok-3-fast-beta",
    "grok-3-mini-beta",
    "grok-3-mini-fast-beta",
    "Qwen2.5-Coder-32B-Instruct",
    "Qwen2.5-72B-Instruct",
    "QwQ-32B-Preview",
    "QwQ-32B",
    "Llama-3.1-Tulu-3-405B",
    "Llama-3.2-11B-Vision-Instruct",
    "Llama-3.2-90B-Vision-Instruct",
    "Meta-Llama-3.2-1B-Instruct",
    "Meta-Llama-3.2-3B-Instruct",
    "Meta-Llama-3.3-70B-Instruct",
    "DeepSeek-V3-0324",
    "DeepSeek-R1-Distill-Llama-70B",
    "deepseek-chat",
    "deepseek-reasoner",
    "gemma-3-27b-it",
    "gemini-2.0-flash",
    "gemini-2.0-flash-lite",
    "gemini-2.0-flash-thinking-exp",
]
