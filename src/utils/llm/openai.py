"""
This file provides an interface to the OpenAI API, encapsulating functions to complete and generate text using language models.
"""

from httpx import AsyncClient
from promplate.llm.openai import AsyncChatComplete, AsyncChatGenerate, AsyncChatOpenAI
from promplate_trace.auto import patch

client = AsyncClient(http2=True)

complete = patch.chat.acomplete(AsyncChatComplete(http_client=client))
generate = patch.chat.agenerate(AsyncChatGenerate(http_client=client))


class OpenAI(AsyncChatOpenAI):
    """
    The OpenAI class acts as a wrapper for AsyncChatOpenAI, providing methods to
    asynchronously send requests to OpenAI's language models for completions and generations.
    """
    def complete(self, prompt, /, **config):  # type: ignore
        """
        Completes the given prompt using the specified configuration for the language model.

        Args:
            prompt: The text to which the model should respond.
            config: Additional configuration settings for the completion request.

        Returns:
            An asynchronous response with the completion generated by the model.
        """
        config = self._run_config | config
        return complete(prompt, **config)

    def generate(self, prompt: str, /, **config):  # type: ignore
        """
        Generates a continuation of the given prompt using the specified configuration.

        Args:
            prompt: The starting text for the generation.
            config: Additional configuration settings for the generation request.

        Returns:
            An asynchronous response with the generated text from the model.
        """
        config = self._run_config | config
        return generate(prompt, **config)


openai = OpenAI().bind(
    model="gpt-3.5-turbo-1106",
    temperature=0.7,
    # response_format={"type": "json_object"},
)
